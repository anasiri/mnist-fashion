{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('fashion-mnist_train.csv')\n",
    "test = pd.read_csv('fashion-mnist_test.csv')\n",
    "\n",
    "classes = {0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for showing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_im(index):\n",
    "    image =np.array(train.loc[index][1:]).reshape(28,28)\n",
    "    print(classes[train['label'][index]])\n",
    "    print('label: ',train['label'][index])\n",
    "    plt.imshow(image,cmap='Greys')\n",
    "def show_im_test(index):\n",
    "    image =np.array(test.loc[index][1:]).reshape(28,28)\n",
    "    print(classes[test['label'][index]])\n",
    "    print('label: ',test['label'][index])\n",
    "    plt.imshow(image,cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 129,898\n",
      "Trainable params: 129,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss = 'categorical_crossentropy',metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('label',axis=1).values.reshape(train.shape[0],28,28,1)/255\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0311 23:49:08.099970  1724 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\envs\\deep_tf2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 14s 231us/sample - loss: 0.5236 - accuracy: 0.8038 - mse: 0.0269\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.3459 - accuracy: 0.8728 - mse: 0.0182\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.3008 - accuracy: 0.8878 - mse: 0.0160\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.2700 - accuracy: 0.8989 - mse: 0.0144\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.2519 - accuracy: 0.9062 - mse: 0.0135\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 12s 206us/sample - loss: 0.2360 - accuracy: 0.9122 - mse: 0.0127\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.2234 - accuracy: 0.9165 - mse: 0.0121\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 12s 208us/sample - loss: 0.2106 - accuracy: 0.9222 - mse: 0.0113\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 13s 208us/sample - loss: 0.2024 - accuracy: 0.9235 - mse: 0.0110\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 0.1948 - accuracy: 0.9270 - mse: 0.0106\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 0.1855 - accuracy: 0.9300 - mse: 0.0101\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 12s 205us/sample - loss: 0.1774 - accuracy: 0.9311 - mse: 0.0098\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.1731 - accuracy: 0.9338 - mse: 0.0095\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 0.1677 - accuracy: 0.9365 - mse: 0.0092\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 12s 196us/sample - loss: 0.1606 - accuracy: 0.9389 - mse: 0.0088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a79cfbb2b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('label',axis=1).values.reshape(test.shape[0],28,28,1)/255\n",
    "y_test = test['label']\n",
    "#y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicating test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n",
      "label:  4\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "show_im_test(i)\n",
    "print(pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1216 - accuracy: 0.9548 - mse: 0.0067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12162161289205153, 0.9548, 0.0066877594]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.2345 - accuracy: 0.9202 - mse: 0.0118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2345278542459011, 0.9202, 0.011773202]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
